## terminal output for the 3 jobs
[cloudera@quickstart hw_3]$ ./iterate_mapreduce.sh pagerank_mapper.py pagerank_reducer.py pagerank_data.txt pr_output 3
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -file pagerank_mapper.py -mapper pagerank_mapper.py -file pagerank_reducer.py -reducer pagerank_reducer.py -input pagerank_data.txt -output pr_output-0
15/09/22 12:49:34 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [pagerank_mapper.py, pagerank_reducer.py] [/usr/jars/hadoop-streaming-2.6.0-cdh5.4.2.jar] /tmp/streamjob6517524472265896508.jar tmpDir=null
15/09/22 12:49:37 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/22 12:49:38 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/22 12:49:39 INFO mapred.FileInputFormat: Total input paths to process : 1
15/09/22 12:49:39 INFO mapreduce.JobSubmitter: number of splits:2
15/09/22 12:49:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1442945303653_0014
15/09/22 12:49:40 INFO impl.YarnClientImpl: Submitted application application_1442945303653_0014
15/09/22 12:49:40 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1442945303653_0014/
15/09/22 12:49:40 INFO mapreduce.Job: Running job: job_1442945303653_0014
15/09/22 12:49:52 INFO mapreduce.Job: Job job_1442945303653_0014 running in uber mode : false
15/09/22 12:49:52 INFO mapreduce.Job:  map 0% reduce 0%
15/09/22 12:50:10 INFO mapreduce.Job:  map 50% reduce 0%
15/09/22 12:50:11 INFO mapreduce.Job:  map 100% reduce 0%
15/09/22 12:50:21 INFO mapreduce.Job:  map 100% reduce 100%
15/09/22 12:50:22 INFO mapreduce.Job: Job job_1442945303653_0014 completed successfully
15/09/22 12:50:22 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=287
		FILE: Number of bytes written=342330
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=373
		HDFS: Number of bytes written=125
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=30570
		Total time spent by all reduces in occupied slots (ms)=8694
		Total time spent by all map tasks (ms)=30570
		Total time spent by all reduce tasks (ms)=8694
		Total vcore-seconds taken by all map tasks=30570
		Total vcore-seconds taken by all reduce tasks=8694
		Total megabyte-seconds taken by all map tasks=31303680
		Total megabyte-seconds taken by all reduce tasks=8902656
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=239
		Map output materialized bytes=293
		Input split bytes=230
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=293
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=602
		CPU time spent (ms)=2210
		Physical memory (bytes) snapshot=588152832
		Virtual memory (bytes) snapshot=4536766464
		Total committed heap usage (bytes)=391979008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=143
	File Output Format Counters 
		Bytes Written=125
15/09/22 12:50:22 INFO streaming.StreamJob: Output directory: pr_output-0
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -file pagerank_mapper.py -mapper pagerank_mapper.py -file pagerank_reducer.py -reducer pagerank_reducer.py -input pr_output-0/part-* -output pr_output-1/
15/09/22 12:50:23 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [pagerank_mapper.py, pagerank_reducer.py] [/usr/jars/hadoop-streaming-2.6.0-cdh5.4.2.jar] /tmp/streamjob948852678985229022.jar tmpDir=null
15/09/22 12:50:26 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/22 12:50:27 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/22 12:50:28 INFO mapred.FileInputFormat: Total input paths to process : 1
15/09/22 12:50:28 INFO mapreduce.JobSubmitter: number of splits:2
15/09/22 12:50:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1442945303653_0015
15/09/22 12:50:29 INFO impl.YarnClientImpl: Submitted application application_1442945303653_0015
15/09/22 12:50:29 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1442945303653_0015/
15/09/22 12:50:29 INFO mapreduce.Job: Running job: job_1442945303653_0015
15/09/22 12:50:41 INFO mapreduce.Job: Job job_1442945303653_0015 running in uber mode : false
15/09/22 12:50:41 INFO mapreduce.Job:  map 0% reduce 0%
15/09/22 12:50:59 INFO mapreduce.Job:  map 50% reduce 0%
15/09/22 12:51:00 INFO mapreduce.Job:  map 100% reduce 0%
15/09/22 12:51:10 INFO mapreduce.Job:  map 100% reduce 100%
15/09/22 12:51:11 INFO mapreduce.Job: Job job_1442945303653_0015 completed successfully
15/09/22 12:51:11 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=318
		FILE: Number of bytes written=342392
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=428
		HDFS: Number of bytes written=130
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=30589
		Total time spent by all reduces in occupied slots (ms)=8740
		Total time spent by all map tasks (ms)=30589
		Total time spent by all reduce tasks (ms)=8740
		Total vcore-seconds taken by all map tasks=30589
		Total vcore-seconds taken by all reduce tasks=8740
		Total megabyte-seconds taken by all map tasks=31323136
		Total megabyte-seconds taken by all reduce tasks=8949760
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=270
		Map output materialized bytes=324
		Input split bytes=240
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=324
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=571
		CPU time spent (ms)=2320
		Physical memory (bytes) snapshot=569565184
		Virtual memory (bytes) snapshot=4527882240
		Total committed heap usage (bytes)=391979008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=188
	File Output Format Counters 
		Bytes Written=130
15/09/22 12:51:11 INFO streaming.StreamJob: Output directory: pr_output-1/
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -file pagerank_mapper.py -mapper pagerank_mapper.py -file pagerank_reducer.py -reducer pagerank_reducer.py -input pr_output-1/part-* -output pr_output-2/
15/09/22 12:51:13 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [pagerank_mapper.py, pagerank_reducer.py] [/usr/jars/hadoop-streaming-2.6.0-cdh5.4.2.jar] /tmp/streamjob6378503240970635243.jar tmpDir=null
15/09/22 12:51:16 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/22 12:51:17 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/09/22 12:51:18 INFO mapred.FileInputFormat: Total input paths to process : 1
15/09/22 12:51:18 INFO mapreduce.JobSubmitter: number of splits:2
15/09/22 12:51:18 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1442945303653_0016
15/09/22 12:51:19 INFO impl.YarnClientImpl: Submitted application application_1442945303653_0016
15/09/22 12:51:19 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1442945303653_0016/
15/09/22 12:51:19 INFO mapreduce.Job: Running job: job_1442945303653_0016
15/09/22 12:51:32 INFO mapreduce.Job: Job job_1442945303653_0016 running in uber mode : false
15/09/22 12:51:32 INFO mapreduce.Job:  map 0% reduce 0%
15/09/22 12:51:48 INFO mapreduce.Job:  map 50% reduce 0%
15/09/22 12:51:49 INFO mapreduce.Job:  map 100% reduce 0%
15/09/22 12:52:00 INFO mapreduce.Job:  map 100% reduce 100%
15/09/22 12:52:00 INFO mapreduce.Job: Job job_1442945303653_0016 completed successfully
15/09/22 12:52:01 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=325
		FILE: Number of bytes written=342409
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=435
		HDFS: Number of bytes written=139
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=28828
		Total time spent by all reduces in occupied slots (ms)=9397
		Total time spent by all map tasks (ms)=28828
		Total time spent by all reduce tasks (ms)=9397
		Total vcore-seconds taken by all map tasks=28828
		Total vcore-seconds taken by all reduce tasks=9397
		Total megabyte-seconds taken by all map tasks=29519872
		Total megabyte-seconds taken by all reduce tasks=9622528
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=277
		Map output materialized bytes=331
		Input split bytes=240
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=331
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=483
		CPU time spent (ms)=2290
		Physical memory (bytes) snapshot=577859584
		Virtual memory (bytes) snapshot=4512358400
		Total committed heap usage (bytes)=391979008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=195
	File Output Format Counters 
		Bytes Written=139
15/09/22 12:52:01 INFO streaming.StreamJob: Output directory: pr_output-2/
## first iteration
[cloudera@quickstart hw_3]$ hdfs dfs -cat pr_output-0/part-00000
A C F 0.1166669	
B D E F 0.2000004	
C A B 0.2000004	
D A B C E F 0.0555556666667	
E F 0.0888890666667	
F B C 0.338889566667	
## second iteration
[cloudera@quickstart hw_3]$ hdfs dfs -cat pr_output-1/part-00000
A C F 0.111111333333	
B D E F 0.280556116666	
C A B 0.238889366666	
D A B C E F 0.0666668	
E F 0.0777779333333	
F B C 0.22500045	
## third iteration
[cloudera@quickstart hw_3]$ hdfs dfs -cat pr_output-2/part-00000
A C F 0.132778043333	
B D E F 0.245278268333	
C A B 0.181389251666	
D A B C E F 0.0935187055553	
E F 0.106852065555	
F B C 0.240185665555
